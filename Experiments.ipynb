{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IOHexperimenter import IOH_function, IOH_logger, IOHexperimenter\n",
    "import numpy as np\n",
    "import sys\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 10000\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# hyperparameters\n",
    "npop = 50 # population size \n",
    "beta = np.pi/36 # 5 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_1(problem):\n",
    "    \"\"\"\n",
    "    This function uses:\n",
    "        - Global Sigma Mutation\n",
    "        - Intermediate Recombination\n",
    "        - (mu + lambda) selection\n",
    "    \"\"\"\n",
    "    n = problem.number_of_variables\n",
    "    \n",
    "    tao_0 = 1/np.sqrt(n) # learning rate (tao 0)\n",
    "    lamda = npop * 7 # offspring population size\n",
    "    \n",
    "    fopt = -sys.maxsize-1\n",
    "    \n",
    "    # Initial Population samples uniformly distributed over the interval (boundaries)\n",
    "    P = np.random.uniform(low=problem.lowerbound[0],high=problem.upperbound[0], size=(npop, n))\n",
    "    \n",
    "    sigma = (problem.upperbound[0]-problem.lowerbound[0])/6 # Global Sigma initialization with feasible range\n",
    "    \n",
    "    # Fitness evaluation of the population\n",
    "    fitness = -1*np.apply_along_axis(problem, 1, P)\n",
    "    \n",
    "    if np.max(fitness) >= fopt:\n",
    "        x_prime = P[np.argmax(fitness)]\n",
    "        fopt = np.max(fitness)\n",
    "    \n",
    "    \n",
    "    ## !! final_target_hit returns True if the optimum has been found.\n",
    "    ## !! evaluations returns the number of function evaluations has been done on the problem. \n",
    "    while not problem.final_target_hit and problem.evaluations < budget * n: \n",
    "        OP = [] # offspring population\n",
    "        \n",
    "        ### Intermediate Recombination\n",
    "        for i in range(lamda):\n",
    "            parent1 = P[np.random.choice(npop)]\n",
    "            parent2 = P[np.random.choice(npop)]\n",
    "            offspring = np.mean((parent1, parent2), axis=0)\n",
    "            OP.append(offspring)\n",
    "        \n",
    "        OP = np.array(OP) # Offspring population\n",
    "        OP_prime = []\n",
    "        \n",
    "        sigma_prime = sigma * np.exp(np.random.normal(0, tao_0))\n",
    "        \n",
    "        ### Mutation\n",
    "        for x_i in OP:\n",
    "            x_i_prime = x_i + np.random.normal(0, sigma_prime) \n",
    "            OP_prime.append(x_i_prime)\n",
    "            \n",
    "        OP_prime = np.array(OP_prime)\n",
    "        \n",
    "        ### Evaluation of (OP_prime + P)\n",
    "        total_pop = np.append(P,OP_prime, axis=0)\n",
    "        fitness = -1*np.apply_along_axis(problem, 1, total_pop)\n",
    "        if np.max(fitness) >= fopt:\n",
    "            x_prime = total_pop[np.argmax(fitness)]\n",
    "            fopt = np.max(fitness)\n",
    "            \n",
    "        ### Selection\n",
    "        top_fits = heapq.nlargest(npop, fitness)\n",
    "        sorter = np.argsort(fitness)\n",
    "        indices = sorter[np.searchsorted(fitness, top_fits, sorter=sorter)]\n",
    "        P = total_pop[indices]\n",
    "\n",
    "    return x_prime, fopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_2(problem):\n",
    "    \"\"\"\n",
    "    This function uses:\n",
    "        - Individual Sigma Mutation\n",
    "        - Intermediate Recombination\n",
    "        - (mu + lambda) selection\n",
    "    \"\"\"\n",
    "    n = problem.number_of_variables\n",
    "    \n",
    "    tao_prime = 1/np.sqrt(2*n) # global learning rate\n",
    "    tao_0 = 1/np.sqrt(2*np.sqrt(n)) # local learning rate\n",
    "    \n",
    "    lamda = npop * 7 # offspring population size\n",
    "    \n",
    "    fopt = -sys.maxsize-1\n",
    "    \n",
    "    # Initial Population samples uniformly distributed over the interval (boundaries)\n",
    "    P = np.random.uniform(low=problem.lowerbound[0],high=problem.upperbound[0], size=(npop, n))\n",
    "    \n",
    "    sigmas = [(problem.upperbound[0]-problem.lowerbound[0])/6]*npop # Individual sigma initialization with feasible range\n",
    "    \n",
    "    # Fitness evaluation of the population\n",
    "    fitness = -1*np.apply_along_axis(problem, 1, P)\n",
    "    \n",
    "    if np.max(fitness) >= fopt:\n",
    "        x_prime = P[np.argmax(fitness)]\n",
    "        fopt = np.max(fitness)\n",
    "    \n",
    "    \n",
    "    ## !! final_target_hit returns True if the optimum has been found.\n",
    "    ## !! evaluations returns the number of function evaluations has been done on the problem. \n",
    "    while not problem.final_target_hit and problem.evaluations < budget * n: \n",
    "        OP = [] # offspring population\n",
    "        \n",
    "        ### Intermediate Recombination\n",
    "        for i in range(lamda):\n",
    "            parent1 = P[np.random.choice(npop)]\n",
    "            parent2 = P[np.random.choice(npop)]\n",
    "            offspring = np.mean((parent1, parent2), axis=0)\n",
    "            OP.append(offspring)\n",
    "        \n",
    "        OP = np.array(OP) # Offspring population\n",
    "        OP_prime = []\n",
    "        sigmas_prime = []\n",
    "        \n",
    "        N_tao_prime = np.random.normal(0, tao_prime)\n",
    "        \n",
    "        ### Mutation\n",
    "        for x_i, sigma_i in zip(OP, sigmas):\n",
    "            sigma_i_prime = sigma_i * np.exp(N_tao_prime + np.random.normal(0, tao_0))\n",
    "            sigmas_prime.append(sigma_i_prime)\n",
    "            \n",
    "            x_i_prime = x_i + np.random.normal(0, sigma_i_prime) \n",
    "            OP_prime.append(x_i_prime)\n",
    "            \n",
    "        OP_prime = np.array(OP_prime)\n",
    "        sigmas = sigmas_prime\n",
    "        \n",
    "        ### Evaluation of (OP_prime + P)\n",
    "        total_pop = np.append(P,OP_prime, axis=0)\n",
    "        fitness = -1*np.apply_along_axis(problem, 1, total_pop)\n",
    "        if np.max(fitness) >= fopt:\n",
    "            x_prime = total_pop[np.argmax(fitness)]\n",
    "            fopt = np.max(fitness)\n",
    "            \n",
    "        ### Selection\n",
    "        top_fits = heapq.nlargest(npop, fitness)\n",
    "        sorter = np.argsort(fitness)\n",
    "        indices = sorter[np.searchsorted(fitness, top_fits, sorter=sorter)]\n",
    "        P = total_pop[indices]\n",
    "\n",
    "    return x_prime, fopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_3(problem):\n",
    "    \"\"\"\n",
    "    This function uses:\n",
    "        - Correlated Mutation\n",
    "        - Intermediate Recombination\n",
    "        - (mu, lambda) selection\n",
    "    \"\"\"\n",
    "    n = problem.number_of_variables\n",
    "    n_q = int(n * (n - 1) / 2)\n",
    "\n",
    "    tao_prime = 1 / np.sqrt(2 * n)  # global learning rate\n",
    "    tao_0 = 1 / np.sqrt(2 * np.sqrt(n))  # local learning rate\n",
    "\n",
    "    lamda = npop * 7  # offspring population size\n",
    "\n",
    "    fopt = -sys.maxsize - 1\n",
    "\n",
    "    # Initial Population samples uniformly distributed over the interval (boundaries)\n",
    "    P = np.random.uniform(low=problem.lowerbound[0], high=problem.upperbound[0], size=(npop, n))\n",
    "\n",
    "    alphas = np.random.uniform(low=-np.pi, high=np.pi, size=n_q)  # rotation angles initialized\n",
    "\n",
    "    OOB_correction = lambda x: x - 2*np.pi*(x / np.abs(x)) if (np.abs(x) > np.pi).any() else x  # out of boundary correction function\n",
    "\n",
    "    sigmas = [(problem.upperbound[0] - problem.lowerbound[0]) / 6] * npop  # Individual sigma initialization with feasible range\n",
    "\n",
    "    # Fitness evaluation of the population\n",
    "    fitness = -1 * np.apply_along_axis(problem, 1, P)\n",
    "\n",
    "    if np.max(fitness) >= fopt:\n",
    "        x_prime = P[np.argmax(fitness)]\n",
    "        fopt = np.max(fitness)\n",
    "\n",
    "    ## !! final_target_hit returns True if the optimum has been found.\n",
    "    ## !! evaluations returns the number of function evaluations has been done on the problem.\n",
    "    while not problem.final_target_hit and problem.evaluations < budget * n:\n",
    "        OP = []  # offspring population\n",
    "        n_q = int(n * (n - 1) / 2)\n",
    "        ### Intermediate Recombination\n",
    "        for i in range(lamda):\n",
    "            parent1 = P[np.random.choice(npop)]\n",
    "            parent2 = P[np.random.choice(npop)]\n",
    "            offspring = np.mean((parent1, parent2), axis=0)\n",
    "            OP.append(offspring)\n",
    "\n",
    "        OP = np.array(OP)  # Offspring population\n",
    "\n",
    "        N_tao_prime = np.random.normal(0, tao_prime)\n",
    "\n",
    "        ### Mutation\n",
    "        # Step size update\n",
    "        sigmas_prime = [sigma * np.exp(N_tao_prime + np.random.normal(0, tao_0)) for sigma in sigmas]\n",
    "\n",
    "        # Rotation angles update\n",
    "\n",
    "        alphas_prime = np.apply_along_axis(OOB_correction, 0, alphas + np.random.normal(0, beta, size=n_q))\n",
    "\n",
    "        \n",
    "\n",
    "        # Correlation of steps sizes\n",
    "        s = np.zeros(n)\n",
    "        for n_i in range(n):\n",
    "            s[n_i] = sigmas_prime[n_i] * np.random.normal(0, 1)  # uncorrelated mutation vector initialization\n",
    "        \n",
    "        for k in range(1, n):\n",
    "            n_i = n-1 - k\n",
    "            n_ii = n-1\n",
    "            for i in range(1, k+1):\n",
    "                d1, d2 = s[n_i], s[n_ii]\n",
    "                s[n_ii] = d1 * np.sin(alphas_prime[n_q-1]) + d2 * np.cos(alphas_prime[n_q-1])\n",
    "                s[n_i] = d1 * np.cos(alphas_prime[n_q-1]) - d2 * np.sin(alphas_prime[n_q-1])\n",
    "                n_ii = n_ii - 1\n",
    "                n_q = n_q - 1\n",
    "\n",
    "        OP_prime = []\n",
    "        for x_i, sigma_i in zip(OP, sigmas_prime):\n",
    "            x_i_prime = x_i + sigma_i * s\n",
    "            OP_prime.append(x_i_prime)\n",
    "        OP_prime = np.array(OP_prime)\n",
    "\n",
    "        ### Evaluation of OP_prime\n",
    "        fitness = -1 * np.apply_along_axis(problem, 1, OP_prime)\n",
    "        if np.max(fitness) >= fopt:\n",
    "            x_prime = OP_prime[np.argmax(fitness)]\n",
    "            fopt = np.max(fitness)\n",
    "\n",
    "        ### Selection\n",
    "        top_fits = heapq.nlargest(npop, fitness)\n",
    "        sorter = np.argsort(fitness)\n",
    "        indices = sorter[np.searchsorted(fitness, top_fits, sorter=sorter)]\n",
    "        P = OP_prime[indices]\n",
    "\n",
    "    return x_prime, fopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    ## Declarations of Ids, instances, and dimensions that the problems to be tested.\n",
    "    problem_id = range(1,25)\n",
    "    instance_id = range(1,26)\n",
    "    dimension = [2,5,20]\n",
    "\n",
    "    ## Declariation of IOHprofiler_csv_logger.\n",
    "    ## 'result' is the name of output folder.\n",
    "    ## 'studentname1_studentname2' represents algorithm name and algorithm info, which will be caption of the algorithm in IOHanalyzer.\n",
    "    logger = IOH_logger(\"./\", \"result-ES3\", \"ES_3\", \"ES_3\")\n",
    "\n",
    "    for p_id in problem_id :\n",
    "        for d in dimension :\n",
    "            for i_id in instance_id:\n",
    "                ## Getting the problem with corresponding id,dimension, and instance.\n",
    "                f = IOH_function(p_id, d, i_id, suite=\"BBOB\")\n",
    "                f.add_logger(logger)\n",
    "                xopt, fopt = ES_3(f)\n",
    "    logger.clear_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ea",
   "language": "python",
   "name": "ea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
